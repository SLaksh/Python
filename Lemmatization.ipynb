{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRMGbxqj2NGj/TUQ4SRyMi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SLaksh/Python/blob/main/Lemmatization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WQ5a6dsmQpt"
      },
      "outputs": [],
      "source": [
        "##   Lemmatization, unlike Stemming, reduces the inflected words properly ensuring that the root word belongs to the language. \n",
        "##         In Lemmatization root word is called Lemma. \n",
        "##       A lemma (plural lemmas or lemmata) is the canonical form, dictionary form, or citation form of a set of words."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "sentence = \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"\n",
        "punctuations=\"?:!.,;\"\n",
        "sentence_words = nltk.word_tokenize(sentence)\n",
        "for word in sentence_words:\n",
        "    if word in punctuations:\n",
        "        sentence_words.remove(word)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oyeGv-gmmSe",
        "outputId": "38f7d381-b6ce-4b44-9b17-b38a8913dc3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "sentence_words\n",
        "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
        "for word in sentence_words:\n",
        "    print (\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71sEPey0nLnx",
        "outputId": "0c1437dc-f18d-4e38-bb6c-226741a1fa38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                Lemma               \n",
            "He                  He                  \n",
            "was                 wa                  \n",
            "running             running             \n",
            "and                 and                 \n",
            "eating              eating              \n",
            "at                  at                  \n",
            "same                same                \n",
            "time                time                \n",
            "He                  He                  \n",
            "has                 ha                  \n",
            "bad                 bad                 \n",
            "habit               habit               \n",
            "of                  of                  \n",
            "swimming            swimming            \n",
            "after               after               \n",
            "playing             playing             \n",
            "long                long                \n",
            "hours               hour                \n",
            "in                  in                  \n",
            "the                 the                 \n",
            "Sun                 Sun                 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## In the  above output, there is no actual root form has been given for any word, this is because they are given without context. \n",
        "##  You need to provide the context in which you want to lemmatize that is the parts-of-speech (POS).\n",
        "##  This is done by giving the value for pos parameter in wordnet_lemmatizer.lemmatize."
      ],
      "metadata": {
        "id": "UA0-s9R3nm2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in sentence_words:\n",
        "    print (\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word, pos=\"v\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94kcquP4n02J",
        "outputId": "890bb220-9c92-4887-889d-39d1565306b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He                  He                  \n",
            "was                 be                  \n",
            "running             run                 \n",
            "and                 and                 \n",
            "eating              eat                 \n",
            "at                  at                  \n",
            "same                same                \n",
            "time                time                \n",
            "He                  He                  \n",
            "has                 have                \n",
            "bad                 bad                 \n",
            "habit               habit               \n",
            "of                  of                  \n",
            "swimming            swim                \n",
            "after               after               \n",
            "playing             play                \n",
            "long                long                \n",
            "hours               hours               \n",
            "in                  in                  \n",
            "the                 the                 \n",
            "Sun                 Sun                 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XNFoS_tAnnQx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}